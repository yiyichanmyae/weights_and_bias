{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diving Deeper into Weights & Biases\n",
    "\n",
    "<!--- @wandbcode{mlops-zoomcamp} -->\n",
    "\n",
    "In this notebook, we will explore the following\n",
    "\n",
    "* Versioning datasets using [Artifacts](https://docs.wandb.ai/guides/artifacts).\n",
    "* Exploring and visualizing our datasets with [Tables](https://docs.wandb.ai/guides/data-vis).\n",
    "* Baseline Experiment with a Random Forest Classification Model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Dataset to Artifacts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `train.csv` and `test.csv` files from [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic/data) and place them in the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a WandB Run\n",
    "wandb.init(project=\"mlops-zoomcamp-wandb\", job_type=\"log_data\")\n",
    "\n",
    "# Log the `data` directory as an artifact\n",
    "artifact = wandb.Artifact('Titanic', type='dataset', metadata={\"Source\": \"https://www.kaggle.com/competitions/titanic/data\"})\n",
    "artifact.add_dir('data')\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "# End the WandB Run\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versioning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a WandB Run\n",
    "wandb.init(project=\"mlops-zoomcamp-wandb\", job_type=\"log_data\")\n",
    "\n",
    "# Fetch the dataset artifact \n",
    "artifact = wandb.use_artifact('geekyrakshit/mlops-zoomcamp-wandb/Titanic:v0', type='dataset')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(artifact_dir, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(artifact_dir, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_examples = int(0.8 * len(train_df))\n",
    "num_val_examples = len(train_df) - num_train_examples\n",
    "\n",
    "print(num_train_examples, num_val_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Split\"] = [\"Train\"] * num_train_examples + [\"Validation\"] * num_val_examples\n",
    "train_df.to_csv(\"data/train.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the `data` directory as an artifact\n",
    "artifact = wandb.Artifact('Titanic', type='dataset', metadata={\"Source\": \"https://www.kaggle.com/competitions/titanic/data\"})\n",
    "artifact.add_dir('data')\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "# End the WandB Run\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a WandB Run\n",
    "wandb.init(project=\"mlops-zoomcamp-wandb\", job_type=\"explore_data\")\n",
    "\n",
    "# Fetch the latest version of the dataset artifact \n",
    "artifact = wandb.use_artifact('geekyrakshit/mlops-zoomcamp-wandb/Titanic:latest', type='dataset')\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# Read the files\n",
    "train_val_df = pd.read_csv(os.path.join(artifact_dir, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(artifact_dir, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables corresponding to datasets\n",
    "train_val_table = wandb.Table(dataframe=train_val_df)\n",
    "test_table = wandb.Table(dataframe=test_df)\n",
    "\n",
    "# Log the tables to Weights & Biases\n",
    "wandb.log({\n",
    "    \"Train-Val-Table\": train_val_table,\n",
    "    \"Test-Table\": test_table\n",
    "})\n",
    "\n",
    "# End the WandB Run\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a WandB Run\n",
    "wandb.init(project=\"mlops-zoomcamp-wandb\", name=\"baseline_experiment-2\", job_type=\"train\")\n",
    "\n",
    "# Fetch the latest version of the dataset artifact \n",
    "artifact = wandb.use_artifact('geekyrakshit/mlops-zoomcamp-wandb/Titanic:latest', type='dataset')\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# Read the files\n",
    "train_val_df = pd.read_csv(os.path.join(artifact_dir, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(artifact_dir, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X_train = pd.get_dummies(train_val_df[features][train_val_df[\"Split\"] == \"Train\"])\n",
    "X_val = pd.get_dummies(train_val_df[features][train_val_df[\"Split\"] == \"Validation\"])\n",
    "y_train = train_val_df[\"Survived\"][train_val_df[\"Split\"] == \"Train\"]\n",
    "y_val = train_val_df[\"Survived\"][train_val_df[\"Split\"] == \"Validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\"n_estimators\": 100, \"max_depth\": 10, \"random_state\": 1}\n",
    "wandb.config = model_params\n",
    "\n",
    "model = RandomForestClassifier(**model_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_probas_train = model.predict_proba(X_train)\n",
    "y_pred_val = model.predict(X_val)\n",
    "y_probas_val = model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\n",
    "    \"Train/Accuracy\": accuracy_score(y_train, y_pred_train),\n",
    "    \"Validation/Accuracy\": accuracy_score(y_val, y_pred_val),\n",
    "    \"Train/Presicion\": precision_score(y_train, y_pred_train),\n",
    "    \"Validation/Presicion\": precision_score(y_val, y_pred_val),\n",
    "    \"Train/Recall\": recall_score(y_train, y_pred_train),\n",
    "    \"Validation/Recall\": recall_score(y_val, y_pred_val),\n",
    "    \"Train/F1-Score\": f1_score(y_train, y_pred_train),\n",
    "    \"Validation/F1-Score\": f1_score(y_val, y_pred_val),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"Not-Survived\", \"Survived\"]\n",
    "\n",
    "wandb.sklearn.plot_class_proportions(y_train, y_val, label_names)\n",
    "wandb.sklearn.plot_summary_metrics(model, X_train, y_train, X_val, y_val)\n",
    "wandb.sklearn.plot_roc(y_val, y_probas_val, labels=label_names)\n",
    "wandb.sklearn.plot_precision_recall(y_val, y_probas_val, labels=label_names)\n",
    "wandb.sklearn.plot_confusion_matrix(y_val, y_pred_val, labels=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model\n",
    "with open(\"random_forest_classifier.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Log your model as a versioned file to Weights & Biases Artifact\n",
    "artifact = wandb.Artifact(f\"titanic-random-forest-model\", type=\"model\")\n",
    "artifact.add_file(\"random_forest_classifier.pkl\")\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "\n",
    "# End the WandB Run\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
